{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train on images split into directories. This assumes we've split\n",
    "our videos into frames and moved them to their respective folders.\n",
    "Use keras 2+ and tensorflow 1+\n",
    "Based on:\n",
    "https://keras.io/preprocessing/image/\n",
    "and\n",
    "https://keras.io/applications/\n",
    "\"\"\"\n",
    "import os\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD, Adagrad, Adam, Nadam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Reshape, LSTM, TimeDistributed, Dropout, Input, Flatten, Lambda, PReLU\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "#from utils.clr.clr_callback import * \n",
    "#from UCFdata import DataSet\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Wrapper \n",
    "import keras.backend as K \n",
    "\n",
    "\n",
    "class DropConnect(Wrapper): \n",
    "    def __init__(self, layer, prob=1., **kwargs): \n",
    "        self.prob = prob \n",
    "        self.layer = layer \n",
    "        super(DropConnect, self).__init__(layer, **kwargs) \n",
    "        if 0. < self.prob < 1.: \n",
    "            self.uses_learning_phase = True \n",
    "\n",
    " \n",
    "    def build(self, input_shape): \n",
    "        if not self.layer.built: \n",
    "            self.layer.build(input_shape) \n",
    "            self.layer.built = True \n",
    "        super(DropConnect, self).build() \n",
    "\n",
    " \n",
    "    def compute_output_shape(self, input_shape): \n",
    "        return self.layer.compute_output_shape(input_shape) \n",
    "\n",
    " \n",
    "    def call(self, x): \n",
    "        if 0. < self.prob < 1.: \n",
    "            self.layer.kernel = K.in_train_phase(K.dropout(self.layer.kernel, self.prob), self.layer.kernel) \n",
    "            self.layer.bias = K.in_train_phase(K.dropout(self.layer.bias, self.prob), self.layer.bias) \n",
    "        return self.layer.call(x) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: Save the min val_loss model in each epoch.\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='incept(global)_lstm_pred.{epoch:03d}-{val_loss:.2f}-{val_acc:.2f}-1134-04172019.hdf5',\n",
    "    verbose=1,\n",
    "    monitor='val_acc',\n",
    "    save_best_only=True)\n",
    "\n",
    "# Helper: Stop when we stop learning.\n",
    "# patience: number of epochs with no improvement after which training will be stopped.\n",
    "#early_stopper = EarlyStopping(patience=10)\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tensorboard = TensorBoard(log_dir='utils/logs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generators():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "          'data/train',\n",
    "          target_size=(224, 224),\n",
    "          batch_size=batch_size,\n",
    "          class_mode='categorical',  # this means our generator will only yield batches of data, no labels\n",
    "          shuffle=False,\n",
    "          classes=['angry','happy','sad','submissive'])\n",
    "\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "          'data/val',\n",
    "          target_size=(224, 224),\n",
    "          batch_size=batch_size,\n",
    "          class_mode='categorical',  # this means our generator will only yield batches of data, no labels\n",
    "          shuffle=False,\n",
    "          classes=['angry','happy','sad','submissive'])\n",
    "    return train_generator, validation_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(weights='imagenet'):\n",
    "    # create the base pre-trained model\n",
    "    base_model = InceptionV3(weights=weights, include_top=False)\n",
    "\n",
    "    x2 = base_model.output\n",
    "    x2 = DropConnect(Dense(2048, activation='relu'), prob=0.5)(x2)\n",
    "    x2 = Reshape((25,2048))(x2)\n",
    "    x2 = LSTM(256,dropout=0.2,input_shape=(25,2048))(x2)\n",
    "    x2 = DropConnect(Dense(64, activation='relu'), prob=0.9)(x2)\n",
    "    predictions = Dense(4, activation='softmax')(x2)\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)    \n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # compile the model (should be done *after* setting layers to non-trainable)\n",
    "    model.compile(optimizer=Adagrad(lr = 0.0001, decay=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_inception_layer(model):\n",
    "    \"\"\"After we fine-tune the dense layers, train deeper.\"\"\"\n",
    "    # we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "    # the first 172 layers and unfreeze the rest:\n",
    "    for layer in model.layers[:172]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[172:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # we need to recompile the model for these modifications to take effect\n",
    "    # we use SGD with a low learning rate\n",
    "    model.compile(\n",
    "        optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, nb_epoch, generators, callbacks=[]):\n",
    "    train_generator, validation_generator = generators\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=23750/25,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=7100/25,\n",
    "        epochs=nb_epoch,\n",
    "        callbacks=callbacks)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(weights_file):\n",
    "\n",
    "    model = get_model()\n",
    "    generators = get_generators()\n",
    "\n",
    "#     if weights_file is None:\n",
    "#         print(\"Training Top layers.\")\n",
    "#         model = train_model(model, 10, generators)\n",
    "#     else:\n",
    "#         print(\"Loading saved model: %s.\" % weights_file)\n",
    "#         model.load_weights(weights_file)\n",
    "\n",
    "#     # Get and train the mid layers.\n",
    "#     print(\"Freezing Top Layers and Getting Mid Layers\")\n",
    "#     model = fine_tune_inception_layer(model)\n",
    "    \n",
    "    print(\"Training Mid layers\")\n",
    "    model = train_model(model, 10, generators,\n",
    "                        [checkpointer, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23750 images belonging to 4 classes.\n",
      "Found 7100 images belonging to 4 classes.\n",
      "Training Mid layers\n",
      "Epoch 1/10\n",
      "950/950 [==============================] - 362s 381ms/step - loss: 1.4391 - acc: 0.4228 - val_loss: 1.4652 - val_acc: 0.3527\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.35268, saving model to incept(global)_lstm_pred.001-1.47-0.35-1134-04172019.hdf5\n",
      "Epoch 2/10\n",
      "950/950 [==============================] - 361s 380ms/step - loss: 1.5763 - acc: 0.2792 - val_loss: 1.4230 - val_acc: 0.3387\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.35268\n",
      "Epoch 3/10\n",
      "950/950 [==============================] - 366s 386ms/step - loss: 1.5256 - acc: 0.2777 - val_loss: 1.4163 - val_acc: 0.2806\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.35268\n",
      "Epoch 4/10\n",
      "950/950 [==============================] - 367s 386ms/step - loss: 1.5085 - acc: 0.2774 - val_loss: 1.3970 - val_acc: 0.3025\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.35268\n",
      "Epoch 5/10\n",
      "950/950 [==============================] - 366s 385ms/step - loss: 1.5082 - acc: 0.2666 - val_loss: 1.3921 - val_acc: 0.2959\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.35268\n",
      "Epoch 6/10\n",
      "950/950 [==============================] - 363s 382ms/step - loss: 1.4761 - acc: 0.2864 - val_loss: 1.3879 - val_acc: 0.2989\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.35268\n",
      "Epoch 7/10\n",
      "950/950 [==============================] - 364s 383ms/step - loss: 1.4733 - acc: 0.2854 - val_loss: 1.3865 - val_acc: 0.2977\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.35268\n",
      "Epoch 8/10\n",
      "950/950 [==============================] - 364s 383ms/step - loss: 1.4729 - acc: 0.2788 - val_loss: 1.3834 - val_acc: 0.3059\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.35268\n",
      "Epoch 9/10\n",
      "950/950 [==============================] - 363s 382ms/step - loss: 1.4613 - acc: 0.2849 - val_loss: 1.3810 - val_acc: 0.3138\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.35268\n",
      "Epoch 10/10\n",
      "950/950 [==============================] - 363s 382ms/step - loss: 1.4808 - acc: 0.2709 - val_loss: 1.3789 - val_acc: 0.3176\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.35268\n"
     ]
    }
   ],
   "source": [
    "batch_size = 25\n",
    "if __name__ == '__main__':\n",
    "    weights_file = None\n",
    "    main(weights_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING PURPOSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14950 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Classify test images set through our CNN.\n",
    "Use keras 2+ and tensorflow 1+\n",
    "It takes a long time for hours.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import operator\n",
    "import random\n",
    "import glob\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# CNN model evaluate\n",
    "test_path = 'data/test' #path to your validation / test videos\n",
    "test_data_gen = ImageDataGenerator(rescale=1. / 255)\n",
    "batch_size = 25\n",
    "test_generator = test_data_gen.flow_from_directory(test_path, target_size=(224, 224),\n",
    "                                                   batch_size=batch_size, classes=['angry','happy','sad','submissive'],\n",
    "                                                   class_mode='categorical',shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained model that has been saved in CNN_train_UCF101.py, your model name maybe is not the same as follow\n",
    "model = load_model('incept(global)_lstm_pred.001-1.47-0.35-1134-04172019.hdf5', custom_objects={'DropConnect':DropConnect})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_num = 14950 #the number of test images. use exactly number generated from generator.\n",
    "test_generator.reset() #to avoid having bugs in generator.\n",
    "# if you dont invoke .reset(), it will starts to mix the order of the array from predicted generator\n",
    "\n",
    "predicted_array = model.predict_generator(generator=test_generator, steps=test_data_num/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14950"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_array) #check if generated data is the same as test_data_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually calculate accuracy for model & template for documentation purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voting accuracy :  0.27424749163879597\n",
      "mean accuracy :  0.27424749163879597\n"
     ]
    }
   ],
   "source": [
    "frame = [] #check all frame names for each validation / test videos\n",
    "filenames = [] #check all filenames for each validation / test videos\n",
    "gt = [] #ground truth storage for each validation / test videos\n",
    "length = [] #how many frames belongs to which test / validation videos\n",
    "final_predicted_array = [] #final predicted results for all videos\n",
    "\n",
    "catfiles = os.listdir(test_path)\n",
    "for i in range(len(catfiles)):\n",
    "    subvideos = os.listdir(os.path.join(test_path,catfiles[i]))\n",
    "    filenames.extend(subvideos)\n",
    "    for j in range(len(subvideos)):\n",
    "        contentvideos = os.listdir(os.path.join(test_path,catfiles[i],subvideos[j]))\n",
    "        frame.append(contentvideos)\n",
    "        length.append(len(contentvideos))\n",
    "        gt.append(i)\n",
    "cum_length = np.cumsum(length)\n",
    "test2 = predicted_array[:cum_length[0]]\n",
    "final_predicted_array.append(test2)\n",
    "for i in range(len(cum_length)-1):\n",
    "    test2 = predicted_array[cum_length[i]:cum_length[i+1]]\n",
    "    final_predicted_array.append(test2)\n",
    "votepred = []\n",
    "meanpred = []\n",
    "\n",
    "for i in range(len(final_predicted_array)):\n",
    "    votectg = np.bincount(np.argmax(final_predicted_array[i], axis=1))\n",
    "    votepred.append(np.argmax(votectg))\n",
    "    meanctg = np.argmax(np.mean(final_predicted_array[i], axis=0))\n",
    "    meanpred.append(meanctg)\n",
    "\n",
    "vote = 0\n",
    "mean = 0\n",
    "for i in range(len(gt)):\n",
    "    if(gt[i] == votepred[i]):\n",
    "        vote += 1\n",
    "    if(gt[i] == meanpred[i]):\n",
    "        mean += 1\n",
    "        \n",
    "vote_acc = vote/len(gt)\n",
    "mean_acc = mean/len(gt)\n",
    "\n",
    "print(\"voting accuracy : \", vote_acc)\n",
    "print(\"mean accuracy : \", mean_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looping method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto looping all available test / validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in range(len(frame)):\n",
    "    #print('filename:',frame[x])\n",
    "    print(color.BOLD + filenames[x] + color.END)\n",
    "    print('number of file:',length[x])\n",
    "    #print('array:',final_predicted_array[x])\n",
    "    avgstr = []\n",
    "    for j in range(final_predicted_array[x].shape[1]):\n",
    "        avg = np.mean(final_predicted_array[x][:,j])\n",
    "        avgstr.append(avg) \n",
    "    predicted_labels, value = max(enumerate(avgstr), key=operator.itemgetter(1))\n",
    "    print(avgstr)\n",
    "    print('ground truth:',gt[x])\n",
    "    print('prediction:', predicted_labels)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Video Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voting accuracy :  0.25\n",
      "mean accuracy :  0.25\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from random import randint\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "dirpath = 'data/test'\n",
    "classes = os.listdir(dirpath)\n",
    "length = []\n",
    "ground_truth = []\n",
    "ctr = 0\n",
    "for i in range(len(classes)):\n",
    "    classpath = os.path.join(dirpath,classes[i])\n",
    "    clip = os.listdir(classpath)\n",
    "    for clp in clip:\n",
    "        clippath = os.path.join(classpath,clp)\n",
    "        vids = os.listdir(clippath)\n",
    "        test = int(clp[-2:]) * len(vids)\n",
    "        if test < ctr:\n",
    "            ground_truth.append(i)\n",
    "            length.append(ctr)\n",
    "            ctr = 0\n",
    "        ctr = test\n",
    "        \n",
    "arraystorage = [[] for i in range(len(length))]\n",
    "votepred = []\n",
    "meanpred = []\n",
    "for i in range(len(length)):\n",
    "    if i == 0:\n",
    "        arraystorage[i] = predicted_array[:length[i]]\n",
    "    else:\n",
    "        arraystorage[i] = predicted_array[length[i-1]:length[i]+length[i-1]]\n",
    "        \n",
    "        \n",
    "for i in arraystorage:\n",
    "    votectg = np.bincount(np.argmax(i, axis=1))\n",
    "    votepred.append(np.argmax(votectg))\n",
    "    meanctg = np.argmax(np.mean(i, axis=0))\n",
    "    meanpred.append(meanctg)\n",
    "\n",
    "vote = 0\n",
    "mean = 0\n",
    "for i in range(len(ground_truth)):\n",
    "    if(ground_truth[i] == votepred[i]):\n",
    "        vote += 1\n",
    "    if(ground_truth[i] == meanpred[i]):\n",
    "        mean += 1\n",
    "        \n",
    "vote_acc = vote/len(ground_truth)\n",
    "mean_acc = mean/len(ground_truth)\n",
    "\n",
    "print(\"voting accuracy : \", vote_acc)\n",
    "print(\"mean accuracy : \", mean_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
