{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train on images split into directories. This assumes we've split\n",
    "our videos into frames and moved them to their respective folders.\n",
    "Use keras 2+ and tensorflow 1+\n",
    "Based on:\n",
    "https://keras.io/preprocessing/image/\n",
    "and\n",
    "https://keras.io/applications/\n",
    "\"\"\"\n",
    "import os\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD, Adagrad, Adam, Nadam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Reshape, LSTM, TimeDistributed, Dropout, Input, Flatten, Lambda, PReLU\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "#from utils.clr.clr_callback import * \n",
    "#from UCFdata import DataSet\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Wrapper \n",
    "import keras.backend as K \n",
    "\n",
    "\n",
    "class DropConnect(Wrapper): \n",
    "    def __init__(self, layer, prob=1., **kwargs): \n",
    "        self.prob = prob \n",
    "        self.layer = layer \n",
    "        super(DropConnect, self).__init__(layer, **kwargs) \n",
    "        if 0. < self.prob < 1.: \n",
    "            self.uses_learning_phase = True \n",
    "\n",
    " \n",
    "    def build(self, input_shape): \n",
    "        if not self.layer.built: \n",
    "            self.layer.build(input_shape) \n",
    "            self.layer.built = True \n",
    "        super(DropConnect, self).build() \n",
    "\n",
    " \n",
    "    def compute_output_shape(self, input_shape): \n",
    "        return self.layer.compute_output_shape(input_shape) \n",
    "\n",
    " \n",
    "    def call(self, x): \n",
    "        if 0. < self.prob < 1.: \n",
    "            self.layer.kernel = K.in_train_phase(K.dropout(self.layer.kernel, self.prob), self.layer.kernel) \n",
    "            self.layer.bias = K.in_train_phase(K.dropout(self.layer.bias, self.prob), self.layer.bias) \n",
    "        return self.layer.call(x) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: Save the min val_loss model in each epoch.\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='simple(local)_lstm_pred.{epoch:03d}-{val_loss:.2f}-{val_acc:.2f}-1134-04172019.hdf5',\n",
    "    verbose=1,\n",
    "    monitor='val_acc',\n",
    "    save_best_only=True)\n",
    "\n",
    "# Helper: Stop when we stop learning.\n",
    "# patience: number of epochs with no improvement after which training will be stopped.\n",
    "#early_stopper = EarlyStopping(patience=10)\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tensorboard = TensorBoard(log_dir='utils/logs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generators():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "          'object_data/train',\n",
    "          target_size=(224, 224),\n",
    "          batch_size=batch_size,\n",
    "          class_mode='categorical',  # this means our generator will only yield batches of data, no labels\n",
    "          shuffle=False,\n",
    "          classes=['angry','happy','sad','submissive'])\n",
    "\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "          'object_data/val',\n",
    "          target_size=(224, 224),\n",
    "          batch_size=batch_size,\n",
    "          class_mode='categorical',  # this means our generator will only yield batches of data, no labels\n",
    "          shuffle=False,\n",
    "          classes=['angry','happy','sad','submissive'])\n",
    "    return train_generator, validation_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "import os\n",
    "\n",
    "\n",
    "def CNN(input_shape, classes, weights_dir, include_top=True):\n",
    "    '''\n",
    "    The CNN for optical flow input.\n",
    "    Since optical flow is not a common image, we cannot finetune pre-trained ResNet (The weights trained on imagenet is\n",
    "    for images and thus is meaningless for optical flow)\n",
    "    :param input_shape: the shape of optical flow input\n",
    "    :param classes: number of classes\n",
    "    :return:\n",
    "    '''\n",
    "    optical_flow_input = Input(shape=input_shape)\n",
    "\n",
    "    x = Convolution2D(96, kernel_size=(7, 7), strides=(2, 2), padding='same', name='tmp_conv1')(optical_flow_input)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = PReLU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Convolution2D(256, kernel_size=(5, 5), strides=(2, 2), padding='same', name='tmp_conv2')(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = PReLU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Convolution2D(512, kernel_size=(3, 3), strides=(1, 1), padding='same', name='tmp_conv3')(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = PReLU()(x)\n",
    "\n",
    "    x = Convolution2D(512, kernel_size=(3, 3), strides=(1, 1), padding='same', name='tmp_conv4')(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = PReLU()(x)\n",
    "\n",
    "    x = Convolution2D(512, kernel_size=(3, 3), strides=(1, 1), padding='same', name='tmp_conv5')(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = PReLU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "#     x = Flatten()(x)\n",
    "#     x = Dense(4096, activation='relu', name='tmp_fc6')(x)\n",
    "#     x = Dropout(0.9)(x)\n",
    "\n",
    "#     x = Dense(2048, activation='relu', name='tmp_fc7')(x)\n",
    "#     x = Dropout(0.9)(x)\n",
    "\n",
    "    if include_top:\n",
    "        x = Dense(classes, activation='softmax', name='tmp_fc101')(x)\n",
    "\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=optical_flow_input, outputs=x, name='temporal_CNN')\n",
    "\n",
    "    \n",
    "    if weights_dir == 'imagenet':\n",
    "        if K.image_dim_ordering() == 'th':\n",
    "            if include_top:\n",
    "                weights_path = get_file('inception_v3_weights_th_dim_ordering_th_kernels.h5',\n",
    "                                        TH_WEIGHTS_PATH,\n",
    "                                        cache_subdir='models',\n",
    "                                        md5_hash='b3baf3070cc4bf476d43a2ea61b0ca5f')\n",
    "            else:\n",
    "                weights_path = get_file('inception_v3_weights_th_dim_ordering_th_kernels_notop.h5',\n",
    "                                        TH_WEIGHTS_PATH_NO_TOP,\n",
    "                                        cache_subdir='models',\n",
    "                                        md5_hash='79aaa90ab4372b4593ba3df64e142f05')\n",
    "            model.load_weights(weights_path)\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image dimension ordering convention '\n",
    "                              '(`image_dim_ordering=\"th\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_dim_ordering=\"tf\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "                convert_all_kernels_in_model(model)\n",
    "    else:\n",
    "        if os.path.exists(weights_dir):\n",
    "            model.load_weights(weights_dir, by_name=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(weights='imagenet'):\n",
    "    # create the base pre-trained model\n",
    "    base_model = CNN((224,224,3),4,weights, include_top=False)\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    \n",
    "    x2 = base_model.output\n",
    "    x2 = Convolution2D(2048, kernel_size=(3, 3), strides=(1, 1))(x2)\n",
    "    x2 = DropConnect(Dense(2048), prob=0.5)(x2)\n",
    "    x2 = PReLU()(x2)\n",
    "    x2 = Reshape((25,2048))(x2)\n",
    "    x2 = LSTM(256,dropout=0.2,input_shape=(25,2048))(x2)\n",
    "    x2 = DropConnect(Dense(64), prob=0.9)(x2)\n",
    "    x2 = PReLU()(x2)\n",
    "    predictions = Dense(4, activation='softmax')(x2)\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # compile the model (should be done *after* setting layers to non-trainable)\n",
    "    model.compile(optimizer=Adagrad(lr=0.00005, decay= 1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_inception_layer(model):\n",
    "    \"\"\"After we fine-tune the dense layers, train deeper.\"\"\"\n",
    "    # we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "    # the first 172 layers and unfreeze the rest:\n",
    "    for layer in model.layers[:172]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[172:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # we need to recompile the model for these modifications to take effect\n",
    "    # we use SGD with a low learning rate\n",
    "    model.compile(\n",
    "        optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, nb_epoch, generators, callbacks=[]):\n",
    "    train_generator, validation_generator = generators\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=23750/25,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=7100/25,\n",
    "        epochs=nb_epoch,\n",
    "        callbacks=callbacks)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(weights_file):\n",
    "\n",
    "    model = get_model()\n",
    "    generators = get_generators()\n",
    "\n",
    "#     if weights_file is None:\n",
    "#         print(\"Training Top layers.\")\n",
    "#         model = train_model(model, 10, generators)\n",
    "#     else:\n",
    "#         print(\"Loading saved model: %s.\" % weights_file)\n",
    "#         model.load_weights(weights_file)\n",
    "\n",
    "#     # Get and train the mid layers.\n",
    "#     print(\"Freezing Top Layers and Getting Mid Layers\")\n",
    "#     model = fine_tune_inception_layer(model)\n",
    "    \n",
    "    print(\"Training Mid layers\")\n",
    "    model = train_model(model, 10, generators,\n",
    "                        [checkpointer, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23750 images belonging to 4 classes.\n",
      "Found 7100 images belonging to 4 classes.\n",
      "Training Mid layers\n",
      "Epoch 1/10\n",
      "950/950 [==============================] - 422s 444ms/step - loss: 1.5135 - acc: 0.4257 - val_loss: 1.3842 - val_acc: 0.2465\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.24648, saving model to simple(local)_lstm_pred.001-1.38-0.25-1134-04172019.hdf5\n",
      "Epoch 2/10\n",
      "950/950 [==============================] - 382s 402ms/step - loss: 1.6504 - acc: 0.2903 - val_loss: 1.3840 - val_acc: 0.2465\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.24648\n",
      "Epoch 3/10\n",
      "950/950 [==============================] - 396s 417ms/step - loss: 1.6305 - acc: 0.2699 - val_loss: 1.3845 - val_acc: 0.2465\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.24648\n",
      "Epoch 4/10\n",
      "950/950 [==============================] - 392s 413ms/step - loss: 1.5489 - acc: 0.2858 - val_loss: 1.3847 - val_acc: 0.2465\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.24648\n",
      "Epoch 5/10\n",
      "950/950 [==============================] - 374s 393ms/step - loss: 1.5605 - acc: 0.2762 - val_loss: 1.3848 - val_acc: 0.2465\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.24648\n",
      "Epoch 6/10\n",
      "950/950 [==============================] - 418s 440ms/step - loss: 1.5173 - acc: 0.2824 - val_loss: 1.3849 - val_acc: 0.2465\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.24648\n",
      "Epoch 7/10\n",
      "950/950 [==============================] - 371s 390ms/step - loss: 1.5025 - acc: 0.2817 - val_loss: 1.3849 - val_acc: 0.2465\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.24648\n",
      "Epoch 8/10\n",
      "950/950 [==============================] - 356s 374ms/step - loss: 1.5058 - acc: 0.2854 - val_loss: 1.3850 - val_acc: 0.2465\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.24648\n",
      "Epoch 9/10\n",
      "950/950 [==============================] - 357s 375ms/step - loss: 1.4719 - acc: 0.3027 - val_loss: 1.3850 - val_acc: 0.2465\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.24648\n",
      "Epoch 10/10\n",
      "950/950 [==============================] - 367s 386ms/step - loss: 1.5075 - acc: 0.2658 - val_loss: 1.3851 - val_acc: 0.2465\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.24648\n"
     ]
    }
   ],
   "source": [
    "batch_size = 25\n",
    "if __name__ == '__main__':\n",
    "    weights_file = None\n",
    "    main(weights_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING PURPOSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14950 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Classify test images set through our CNN.\n",
    "Use keras 2+ and tensorflow 1+\n",
    "It takes a long time for hours.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import operator\n",
    "import random\n",
    "import glob\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# CNN model evaluate\n",
    "test_path = 'object_data/test' #path to your validation / test videos\n",
    "test_data_gen = ImageDataGenerator(rescale=1. / 255)\n",
    "batch_size = 25\n",
    "test_generator = test_data_gen.flow_from_directory(test_path, target_size=(224, 224),\n",
    "                                                   batch_size=batch_size, classes=['angry','happy','sad','submissive'],\n",
    "                                                   class_mode='categorical',shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained model that has been saved in CNN_train_UCF101.py, your model name maybe is not the same as follow\n",
    "model = load_model('simple(local)_lstm_pred.001-1.38-0.25-1134-04172019.hdf5', custom_objects={'DropConnect':DropConnect})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_num = 14950 #the number of test images. use exactly number generated from generator.\n",
    "test_generator.reset() #to avoid having bugs in generator.\n",
    "# if you dont invoke .reset(), it will starts to mix the order of the array from predicted generator\n",
    "\n",
    "predicted_array = model.predict_generator(generator=test_generator, steps=test_data_num/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14950"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_array) #check if generated data is the same as test_data_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually calculate accuracy for model & template for documentation purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voting accuracy :  0.33444816053511706\n",
      "mean accuracy :  0.33444816053511706\n"
     ]
    }
   ],
   "source": [
    "frame = [] #check all frame names for each validation / test videos\n",
    "filenames = [] #check all filenames for each validation / test videos\n",
    "gt = [] #ground truth storage for each validation / test videos\n",
    "length = [] #how many frames belongs to which test / validation videos\n",
    "final_predicted_array = [] #final predicted results for all videos\n",
    "\n",
    "catfiles = os.listdir(test_path)\n",
    "for i in range(len(catfiles)):\n",
    "    subvideos = os.listdir(os.path.join(test_path,catfiles[i]))\n",
    "    filenames.extend(subvideos)\n",
    "    for j in range(len(subvideos)):\n",
    "        contentvideos = os.listdir(os.path.join(test_path,catfiles[i],subvideos[j]))\n",
    "        frame.append(contentvideos)\n",
    "        length.append(len(contentvideos))\n",
    "        gt.append(i)\n",
    "cum_length = np.cumsum(length)\n",
    "test2 = predicted_array[:cum_length[0]]\n",
    "final_predicted_array.append(test2)\n",
    "for i in range(len(cum_length)-1):\n",
    "    test2 = predicted_array[cum_length[i]:cum_length[i+1]]\n",
    "    final_predicted_array.append(test2)\n",
    "votepred = []\n",
    "meanpred = []\n",
    "\n",
    "for i in range(len(final_predicted_array)):\n",
    "    votectg = np.bincount(np.argmax(final_predicted_array[i], axis=1))\n",
    "    votepred.append(np.argmax(votectg))\n",
    "    meanctg = np.argmax(np.mean(final_predicted_array[i], axis=0))\n",
    "    meanpred.append(meanctg)\n",
    "\n",
    "vote = 0\n",
    "mean = 0\n",
    "for i in range(len(gt)):\n",
    "    if(gt[i] == votepred[i]):\n",
    "        vote += 1\n",
    "    if(gt[i] == meanpred[i]):\n",
    "        mean += 1\n",
    "        \n",
    "vote_acc = vote/len(gt)\n",
    "mean_acc = mean/len(gt)\n",
    "\n",
    "print(\"voting accuracy : \", vote_acc)\n",
    "print(\"mean accuracy : \", mean_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looping method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto looping all available test / validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in range(len(frame)):\n",
    "    #print('filename:',frame[x])\n",
    "    print(color.BOLD + filenames[x] + color.END)\n",
    "    print('number of file:',length[x])\n",
    "    #print('array:',final_predicted_array[x])\n",
    "    avgstr = []\n",
    "    for j in range(final_predicted_array[x].shape[1]):\n",
    "        avg = np.mean(final_predicted_array[x][:,j])\n",
    "        avgstr.append(avg) \n",
    "    predicted_labels, value = max(enumerate(avgstr), key=operator.itemgetter(1))\n",
    "    print(avgstr)\n",
    "    print('ground truth:',gt[x])\n",
    "    print('prediction:', predicted_labels)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test By Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voting accuracy :  0.2727272727272727\n",
      "mean accuracy :  0.2727272727272727\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from random import randint\n",
    "import random\n",
    "\n",
    "\n",
    "dirpath = 'data/test'\n",
    "classes = os.listdir(dirpath)\n",
    "length = []\n",
    "ground_truth = []\n",
    "ctr = 0\n",
    "for i in range(len(classes)):\n",
    "    classpath = os.path.join(dirpath,classes[i])\n",
    "    clip = os.listdir(classpath)\n",
    "    for clp in clip:\n",
    "        clippath = os.path.join(classpath,clp)\n",
    "        vids = os.listdir(clippath)\n",
    "        test = int(clp[-2:]) * len(vids)\n",
    "        if test < ctr:\n",
    "            ground_truth.append(i)\n",
    "            length.append(ctr)\n",
    "            ctr = 0\n",
    "        ctr = test\n",
    "        \n",
    "arraystorage = [[] for i in range(len(length))]\n",
    "votepred = []\n",
    "meanpred = []\n",
    "for i in range(len(length)):\n",
    "    if i == 0:\n",
    "        arraystorage[i] = predicted_array[:length[i]]\n",
    "    else:\n",
    "        arraystorage[i] = predicted_array[length[i-1]:length[i]+length[i-1]]\n",
    "        \n",
    "        \n",
    "for i in arraystorage:\n",
    "    votectg = np.bincount(np.argmax(i, axis=1))\n",
    "    votepred.append(np.argmax(votectg))\n",
    "    meanctg = np.argmax(np.mean(i, axis=0))\n",
    "    meanpred.append(meanctg)\n",
    "\n",
    "vote = 0\n",
    "mean = 0\n",
    "for i in range(len(ground_truth)):\n",
    "    if(ground_truth[i] == votepred[i]):\n",
    "        vote += 1\n",
    "    if(ground_truth[i] == meanpred[i]):\n",
    "        mean += 1\n",
    "        \n",
    "vote_acc = vote/len(ground_truth)\n",
    "mean_acc = mean/len(ground_truth)\n",
    "\n",
    "print(\"voting accuracy : \", vote_acc)\n",
    "print(\"mean accuracy : \", mean_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
